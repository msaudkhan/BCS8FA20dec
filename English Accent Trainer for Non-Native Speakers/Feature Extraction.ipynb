{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ireland      5000\n",
      "england      5000\n",
      "scotland     5000\n",
      "indian       5000\n",
      "us           5000\n",
      "australia    5000\n",
      "Name: accent, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 5000/5000 [21:42<00:00,  3.84it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 5000/5000 [29:41<00:00,  2.81it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 5000/5000 [31:22<00:00,  2.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 5000/5000 [33:26<00:00,  2.49it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 5000/5000 [30:31<00:00,  2.73it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 5000/5000 [31:22<00:00,  2.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 5000/5000 [42:45<00:00,  1.95it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 5000/5000 [36:48<00:00,  2.26it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 5000/5000 [32:21<00:00,  2.57it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 5000/5000 [34:30<00:00,  2.41it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 5000/5000 [47:48<00:00,  1.74it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 5000/5000 [38:58<00:00,  2.14it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import pydub\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "def read_df(file):\n",
    "    df = pd.read_csv(file, sep='\\t')\n",
    "    df_us = df[df['accent']=='us'].sample(5000)\n",
    "    df_ind = df[df['accent']=='indian'].sample(5000)\n",
    "    df_uk = df[df['accent']=='england'].sample(5000)\n",
    "    df_aus = df[df['accent']=='australia'].sample(5000)\n",
    "    df_ire = df[df['accent']=='ireland'].sample(5000)\n",
    "    df_scot = df[df['accent']=='scotland'].sample(5000)\n",
    "\n",
    "\n",
    "\n",
    "    df = df_us.append(df_ind)\n",
    "    df = df.append(df_uk)\n",
    "    df = df.append(df_aus)\n",
    "    df = df.append(df_ire)\n",
    "    df = df.append(df_scot)\n",
    "    \n",
    "    df.drop(['client_id', 'sentence', 'up_votes', 'down_votes', 'age', 'gender'],\n",
    "        axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def mp3towav(df,col):\n",
    "    for filename in tqdm(df[col]):\n",
    "        pydub.AudioSegment.from_mp3(\"D:/UzairDataSet/en/clips/{}\".format(filename)).export(\"D:/pracrice/{}\".format(filename), format=\"wav\")\n",
    "\n",
    "        \n",
    "def wavtomfcc( file_path):\n",
    "        wave, sr = librosa.load(file_path, mono=True)\n",
    "        mfcc = librosa.feature.mfcc(wave, sr=sr, n_mfcc=13)\n",
    "        return mfcc\n",
    "\n",
    "def create_mfcc(df,col):\n",
    "        list_of_mfccs = []\n",
    "        \n",
    "        us = df[df['accent']=='us']\n",
    "        for wav in tqdm(us[col]):\n",
    "            file_name = 'D:/All Classes/{}.wav'.format(wav)\n",
    "            mfcc = wavtomfcc(file_name)\n",
    "            list_of_mfccs.append(mfcc)\n",
    "\n",
    "        uk = df[df['accent']=='england']\n",
    "        for wav in tqdm(uk[col]):\n",
    "            file_name = 'D:/All Classes/{}.wav'.format(wav)\n",
    "            mfcc = wavtomfcc(file_name)\n",
    "            list_of_mfccs.append(mfcc)\n",
    "\n",
    "        aus = df[df['accent']=='australia']\n",
    "        for wav in tqdm(aus[col]):\n",
    "            file_name = 'D:/All Classes/{}.wav'.format(wav)\n",
    "            mfcc = wavtomfcc(file_name)\n",
    "            list_of_mfccs.append(mfcc)\n",
    "\n",
    "        ire = df[df['accent']=='ireland']\n",
    "        for wav in tqdm(ire[col]):\n",
    "            file_name = 'D:/All Classes/{}.wav'.format(wav)\n",
    "            mfcc = wavtomfcc(file_name)\n",
    "            list_of_mfccs.append(mfcc)\n",
    "\n",
    "        scot = df[df['accent']=='scotland']\n",
    "        for wav in tqdm(scot[col]):\n",
    "            file_name = 'D:/All Classes/{}.wav'.format(wav)\n",
    "            mfcc = wavtomfcc(file_name)\n",
    "            list_of_mfccs.append(mfcc)\n",
    "\n",
    "        \n",
    "        ind = df[df['accent']=='indian']\n",
    "        for wav in tqdm(ind[col]):\n",
    "            file_name = 'D:/All Classes/{}.wav'.format(wav)\n",
    "            mfcc = wavtomfcc(file_name)\n",
    "            list_of_mfccs.append(mfcc)\n",
    "        return list_of_mfccs\n",
    "\n",
    "def resize_mfcc(list_of_mfccs):\n",
    "        target_size = 64\n",
    "        resized_mfcc = [librosa.util.fix_length(mfcc, target_size, axis=1) for mfcc in list_of_mfccs]\n",
    "        resized_mfcc = [np.vstack((np.zeros((3, target_size)), mfcc)) for mfcc in resized_mfcc]\n",
    "        return resized_mfcc\n",
    "\n",
    "\n",
    "def label_samples(df):\n",
    "        y_labels = np.array(df['accent'])\n",
    "        y = []\n",
    "        for label in y_labels:\n",
    "            if label == 'us':\n",
    "                y.append(0)\n",
    "            elif label == 'indian':\n",
    "                y.append(1)\n",
    "            elif label == 'england':\n",
    "                y.append(2)\n",
    "            elif label == 'australia':\n",
    "                y.append(3)\n",
    "            elif label == 'ireland':\n",
    "                y.append(4)\n",
    "            elif label == 'scotland':\n",
    "                y.append(5)\n",
    "        \n",
    "        \n",
    "        return y\n",
    "      \n",
    "\n",
    "\n",
    "def split_data(X,y):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, shuffle = True, test_size=0.25)\n",
    "        X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, stratify=y_test, shuffle = True, test_size=0.3)\n",
    "        X_train = np.array(X_train).reshape(-1, 16, 64)\n",
    "        X_test = np.array(X_test).reshape(-1, 16, 64)\n",
    "        X_val = np.array(X_val).reshape(-1, 16, 64)\n",
    "        y_train = np.array(y_train).reshape(-1, 1)\n",
    "        y_test = np.array(y_test).reshape(-1,1)\n",
    "        y_val = np.array(y_val).reshape(-1,1)\n",
    "        return X_train, X_test,X_val,y_train, y_test,y_val\n",
    "\n",
    "def standardize_mfcc(X_train, X_test,X_val):\n",
    "        train_mean = X_train.mean()\n",
    "        train_std = X_train.std()\n",
    "        X_train_std = (X_train-train_mean)/train_std\n",
    "        X_test_std = (X_test-train_mean)/train_std\n",
    "        X_val_std = (X_val-train_mean)/train_std\n",
    "        return X_train_std,X_test_std,X_val_std\n",
    "\n",
    "    \n",
    "\n",
    "def save_mfccs(X_train_std,X_test_std,X_val_std,y_train, y_test,y_val):\n",
    "        np.save('X_train_moz_6.npy', X_train_std)\n",
    "        np.save('X_test_moz_6.npy', X_test_std)\n",
    "        np.save('X_val_moz_6.npy', X_val_std)\n",
    "        np.save('y_train_moz_6.npy', y_train)\n",
    "        np.save('y_test_moz_6.npy', y_test)\n",
    "        np.save('y_val_moz_6.npy', y_val)\n",
    "\n",
    "# 354, 293, 61\n",
    "if __name__ == '__main__':\n",
    "    df = read_df('D:/UzairDataSet/en/validated.tsv')\n",
    "    #print(df['accent'].value_counts())\n",
    "    mp3towav(df,'path')\n",
    "    list_of_mfccs=[]\n",
    "    list_of_mfccs=create_mfcc(df,'path')\n",
    "    X=resize_mfcc(list_of_mfccs)\n",
    "    y=label_samples(df)\n",
    "    print(y)\n",
    "    X_train, X_test,X_val,y_train, y_test,y_val=split_data(X,y)\n",
    "    X_train_std,X_test_std,X_val_std=standardize_mfcc(X_train, X_test,X_val)\n",
    "    save_mfccs(X_train_std,X_test_std,X_val_std,y_train, y_test,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='Downloads/chunk123.wav'>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "\n",
    "sound = AudioSegment.from_wav(\"Downloads/Recording (6).wav\")\n",
    "chunks = split_on_silence(sound, \n",
    "    # must be silent for at least half a second\n",
    "    min_silence_len=500,silence_thresh=-40,\n",
    "    keep_silence=300\n",
    ")\n",
    "abchunks=0\n",
    "for i in range(0,len(chunks)):\n",
    "    abchunks+=chunks[i]\n",
    "\n",
    "abchunks.export(\"Downloads/chunk123.wav\", format=\"wav\")    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "#for i, chunk in enumerate(chunks):\n",
    "#    chunk.export(\"Downloads/chunk{0}.wav\".format(i), format=\"wav\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
